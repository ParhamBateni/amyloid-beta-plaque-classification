beta: 1.0
feature_extractor:
  dropout_rate: 0.2
  feature_extractor: "Sequential(\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2,\
    \ 2), padding=(3, 3), bias=False)\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): MaxPool2d(kernel_size=3,\
    \ stride=2, padding=1, dilation=1, ceil_mode=False)\n  (4): Sequential(\n    (0):\
    \ BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1),\
    \ padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n \
    \     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),\
    \ bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64,\
    \ 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1):\
    \ BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3,\
    \ 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n\
    \  (5): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3,\
    \ 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu):\
    \ ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,\
    \ 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      (downsample): Sequential(\n  \
    \      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n \
    \       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3,\
    \ 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu):\
    \ ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,\
    \ 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n    )\n  )\n  (6): Sequential(\n   \
    \ (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2,\
    \ 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n \
    \     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128,\
    \ 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256,\
    \ eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n \
    \   )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3),\
    \ stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05,\
    \ momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n\
    \      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n    )\n  )\n  (7): Sequential(\n    (0): BasicBlock(\n\
    \      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1,\
    \ 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2):\
    \ Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\
    \      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1,\
    \ 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,\
    \ affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n\
    \      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1,\
    \ 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True,\
    \ track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2):\
    \ Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n\
    \      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\
    \    )\n  )\n  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n  (9): Flatten(start_dim=1,\
    \ end_dim=-1)\n)"
  freeze: false
  input_dim:
  - 224
  - 224
  model_name: resnet18
  output_size: 64
  pretrained: true
  unfreeze_after_n_epochs: 0
  unfreeze_last_n_blocks: 0
latent_dim: 64
optimizer: <class 'torch.optim.adamw.AdamW'>
optimizer_kwargs:
  lr: 0.0001
  weight_decay: 1.0e-05
reconstruction_loss: mse
